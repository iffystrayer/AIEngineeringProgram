#!/usr/bin/env python3
"""
End-to-End U-AIP Workflow Simulation

This script demonstrates the complete U-AIP Scoping Assistant workflow
from session creation through charter export, simulating a real-world
AI project evaluation.

Demonstrates:
1. Session creation and database persistence
2. All 5 stage evaluations with reflection agent validation
3. Cross-stage consistency checking
4. Charter generation and multi-format export
5. Database storage and retrieval

This script uses REAL components where available and clearly marks
simulated sections for future implementation.
"""

import asyncio
import os
import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path
from uuid import uuid4

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.table import Table

# Real components
from src.database.connection import DatabaseConfig, DatabaseManager
from src.database.repositories.charter_repository import CharterRepository
from src.database.repositories.session_repository import SessionRepository
from src.export import CharterDocumentGenerator
from src.models.schemas import (
    AIProjectCharter,
    Citation,
    ContinuousMonitoringPlan,
    DataQualityScorecard,
    DataSource,
    EthicalPrinciple,
    EthicalRisk,
    EthicalRiskReport,
    ExplainabilityRequirements,
    FAIRAssessment,
    FeasibilityLevel,
    Feature,
    FeedbackMechanism,
    GovernanceDecision,
    HCISpec,
    InfrastructureReport,
    JourneyMap,
    JourneyStage,
    KPI,
    LabelingStrategy,
    MetricAlignmentMatrix,
    MitigationStrategy,
    MLArchetype,
    OutputDefinition,
    Persona,
    ProblemStatement,
    QualityDimension,
    RiskLevel,
    ScopeDefinition,
    FeatureAccessibilityReport,
    Session,
    SessionStatus,
    TechnicalMetric,
    CausalLink,
    ValidationPlan,
    UserContext,
)

console = Console()


# =============================================================================
# SIMULATION DATA - Sample Churn Prediction Project
# =============================================================================


def create_sample_charter_data() -> AIProjectCharter:
    """Create sample charter data for demonstration."""
    # Stage 1: Problem Statement
    problem_statement = ProblemStatement(
        business_objective="Reduce B2B customer churn from current 15% to 10% within 6 months",
        ai_necessity_justification=(
            "Customer churn patterns are complex and multifactorial. Traditional rule-based "
            "approaches have proven insufficient. ML can identify non-obvious patterns and early "
            "warning signals in customer behavior, interaction history, and product usage."
        ),
        input_features=[
            Feature(
                name="customer_lifetime_value",
                data_type="float",
                description="Total revenue generated by customer over their lifetime",
                source_system="CRM Database (Salesforce)",
                availability_in_production=True,
                access_latency_ms=50,
            ),
            Feature(
                name="support_ticket_count_30d",
                data_type="integer",
                description="Number of support tickets in last 30 days",
                source_system="Support System (Zendesk)",
                availability_in_production=True,
                access_latency_ms=100,
            ),
            Feature(
                name="product_usage_score",
                data_type="float",
                description="Composite score of product feature usage",
                source_system="Product Analytics (Mixpanel)",
                availability_in_production=True,
                access_latency_ms=75,
            ),
            Feature(
                name="last_interaction_days",
                data_type="integer",
                description="Days since last customer interaction",
                source_system="Engagement Tracker",
                availability_in_production=True,
                access_latency_ms=30,
            ),
        ],
        target_output=OutputDefinition(
            name="churn_probability_30d",
            type="continuous probability",
            description="Probability of customer churning within next 30 days",
            possible_values=None,
            units="probability (0.0-1.0)",
        ),
        ml_archetype=MLArchetype.CLASSIFICATION,
        ml_archetype_justification=(
            "Binary classification problem: predict whether customer will churn (1) "
            "or remain (0) within 30-day window. Model outputs probability score."
        ),
        scope_boundaries=ScopeDefinition(
            in_scope=[
                "B2B Enterprise tier customers only ($10K+ ARR)",
                "Customers with >3 months tenure",
                "Active product users (>1 login/month)",
            ],
            out_of_scope=[
                "B2C customers",
                "Small business tier (<$10K ARR)",
                "Customers in trial period",
                "Dormant accounts (no logins >90 days)",
            ],
            assumptions=[
                "Historical churn patterns are representative of future",
                "Customer behavior data quality remains consistent",
                "Product feature set remains stable",
            ],
            constraints=[
                "Must deploy within 3 months",
                "Model inference <500ms",
                "Budget: $100K for development + $30K/year operations",
            ],
        ),
        feature_availability=FeatureAccessibilityReport(
            all_features_available=True,
            unavailable_features=[],
            latency_concerns=["Support system has occasional 200ms spikes"],
            access_method_issues=[],
        ),
        created_at=datetime.now(timezone.utc),
        version="1.0",
    )

    # Stage 2: Metric Alignment Matrix
    metric_alignment = MetricAlignmentMatrix(
        business_kpis=[
            KPI(
                name="Customer Retention Rate",
                description="Percentage of customers retained month-over-month",
                current_baseline=85.0,
                target_value=90.0,
                target_timeframe="6 months",
                measurement_method="Monthly cohort analysis from CRM",
                business_impact="$2.5M annual recurring revenue protection",
            ),
            KPI(
                name="Retention Campaign Efficiency",
                description="Cost per successfully retained at-risk customer",
                current_baseline=5000.0,
                target_value=2500.0,
                target_timeframe="6 months",
                measurement_method="Campaign cost / successful interventions",
                business_impact="$500K annual savings on retention spend",
            ),
        ],
        model_metrics=[
            TechnicalMetric(
                name="Precision @ Top 10%",
                description="Precision when predicting top 10% highest-risk customers",
                target_threshold=0.75,
                measurement_method="Holdout test set evaluation",
            ),
            TechnicalMetric(
                name="Recall @ Threshold 0.5",
                description="Percentage of actual churners correctly identified",
                target_threshold=0.70,
                measurement_method="Holdout test set evaluation",
            ),
        ],
        causal_pathways=[
            CausalLink(
                model_metric="Precision @ Top 10%",
                business_kpi="Retention Campaign Efficiency",
                causal_mechanism=(
                    "High precision → fewer false positives → less wasted campaign spend "
                    "→ lower cost per successful retention"
                ),
                assumptions=[
                    "Retention campaigns are effective on truly at-risk customers",
                    "False positives result in wasted outreach",
                ],
                potential_failure_modes=[
                    "Campaign fatigue even with accurate targeting",
                    "External market factors affecting retention",
                ],
            ),
            CausalLink(
                model_metric="Recall @ Threshold 0.5",
                business_kpi="Customer Retention Rate",
                causal_mechanism=(
                    "High recall → more at-risk customers identified → more successful "
                    "interventions → higher retention rate"
                ),
                assumptions=[
                    "Identified at-risk customers can be successfully retained",
                    "30-day window provides sufficient intervention time",
                ],
                potential_failure_modes=[
                    "Some churn reasons are unaddressable (e.g., budget cuts)",
                    "Intervention resources are limited",
                ],
            ),
        ],
        actionability_window=timedelta(days=30),
        causal_impact_plan=ValidationPlan(
            validation_method="A/B test: model-guided campaigns vs. control",
            data_requirements=[
                "Campaign engagement data",
                "Actual churn outcomes",
                "Intervention timestamps",
            ],
            timeline="3 months pilot, 6 months full deployment",
            success_criteria="15% improvement in retention vs. control group",
        ),
        created_at=datetime.now(timezone.utc),
        version="1.0",
    )

    # Stage 3: Data Quality Scorecard
    data_quality = DataQualityScorecard(
        data_sources=[
            DataSource(
                name="CRM Database (Salesforce)",
                type="Cloud database (PostgreSQL replica)",
                description="Customer master data, transaction history, account status",
                size="2.5M customer records, 15M transactions, 500GB total",
                update_frequency="Real-time sync (15-minute lag)",
                access_method="REST API + SQL read replica",
                quality_assessment={
                    QualityDimension.ACCURACY: 9,
                    QualityDimension.COMPLETENESS: 8,
                    QualityDimension.CONSISTENCY: 9,
                    QualityDimension.TIMELINESS: 10,
                    QualityDimension.VALIDITY: 9,
                    QualityDimension.INTEGRITY: 10,
                },
            ),
            DataSource(
                name="Product Analytics (Mixpanel)",
                type="Event streaming (Kafka → S3)",
                description="Product feature usage, user sessions, engagement events",
                size="100M events/month, 2TB total",
                update_frequency="Real-time streaming",
                access_method="S3 batch files + Streaming API",
                quality_assessment={
                    QualityDimension.ACCURACY: 8,
                    QualityDimension.COMPLETENESS: 7,
                    QualityDimension.CONSISTENCY: 8,
                    QualityDimension.TIMELINESS: 10,
                    QualityDimension.VALIDITY: 8,
                    QualityDimension.INTEGRITY: 9,
                },
            ),
        ],
        quality_scores={
            QualityDimension.ACCURACY: 8,
            QualityDimension.COMPLETENESS: 7,
            QualityDimension.CONSISTENCY: 9,
            QualityDimension.TIMELINESS: 10,
            QualityDimension.VALIDITY: 8,
            QualityDimension.INTEGRITY: 9,
        },
        labeling_strategy=LabelingStrategy(
            labeling_method="Supervised learning with historical churn labels",
            estimated_cost=8000.0,
            estimated_time="3 weeks",
            quality_assurance_process=(
                "10% manual validation by customer success team; Cross-validation with "
                "accounting system churn records"
            ),
            annotator_requirements=[
                "Data analyst with SQL expertise",
                "CS team member for validation",
            ],
        ),
        fair_compliance=FAIRAssessment(
            findable=True,
            accessible=True,
            interoperable=True,
            reusable=True,
            gaps=[],
            remediation_plan="All FAIR principles met; no remediation needed",
        ),
        infrastructure_readiness=InfrastructureReport(
            storage_capacity="Sufficient: 100TB available in data lake",
            compute_resources="8 GPU instances (V100) available for training",
            pipeline_maturity="Production-ready ETL pipelines exist",
            gaps=["Need real-time feature serving layer"],
            estimated_setup_cost=15000.0,
        ),
        overall_feasibility=FeasibilityLevel.HIGH,
        created_at=datetime.now(timezone.utc),
        version="1.0",
    )

    # Stage 4: User Context
    user_context = UserContext(
        user_personas=[
            Persona(
                name="Sarah Chen - Enterprise Customer Success Manager",
                role="Customer Success Manager",
                goals=[
                    "Proactively prevent customer churn",
                    "Prioritize highest-value at-risk accounts",
                    "Maximize retention campaign ROI",
                ],
                pain_points=[
                    "Too many alerts - can't prioritize effectively",
                    "Doesn't trust 'black box' predictions",
                    "Needs to explain recommendations to exec team",
                ],
                technical_proficiency="intermediate",
                ai_interaction_frequency="daily",
                decision_authority="High - can initiate retention campaigns up to $50K",
                research_evidence="Interviews with 5 CSMs + survey of 20 CS team members",
                data_access_level="Full access to CRM and customer data",
            ),
        ],
        user_journey_map=JourneyMap(
            stages=[
                JourneyStage(
                    stage_name="Morning Dashboard Review",
                    user_actions=[
                        "Log into dashboard",
                        "Review churn risk scores",
                        "Identify top 10 at-risk accounts",
                    ],
                    pain_points=["Too many low-priority alerts", "Unclear prioritization"],
                    ai_touchpoints=["Risk score display", "Account ranking"],
                    success_criteria=["Clear top 10 list in <2 minutes"],
                ),
                JourneyStage(
                    stage_name="Account Investigation",
                    user_actions=[
                        "Drill into high-risk account details",
                        "Review churn risk factors",
                        "Check intervention history",
                    ],
                    pain_points=["Need to understand WHY account is at risk"],
                    ai_touchpoints=["Feature importance explanations", "Risk factor breakdown"],
                    success_criteria=["Understand root cause in <5 minutes"],
                ),
                JourneyStage(
                    stage_name="Intervention Decision",
                    user_actions=[
                        "Decide on intervention approach",
                        "Document decision rationale",
                        "Schedule outreach",
                    ],
                    pain_points=["Need to justify decisions to management"],
                    ai_touchpoints=["Recommended interventions", "Success probability"],
                    success_criteria=["Confident decision with clear rationale"],
                ),
            ],
            critical_decision_points=[
                "Which 10 accounts to prioritize this week?",
                "What intervention strategy for each account?",
                "When to escalate to senior leadership?",
            ],
            risk_areas=["Over-reliance on model without human judgment"],
        ),
        hci_requirements=HCISpec(
            interface_type="Web dashboard (embedded in Salesforce)",
            response_time_requirement="<1 second for risk score retrieval",
            accessibility_requirements=["WCAG 2.1 AA compliance", "Screen reader support"],
            error_handling_strategy="Graceful degradation with historical averages if model unavailable",
        ),
        interpretability_needs=ExplainabilityRequirements(
            required_level="high",
            explanation_method="SHAP values + feature importance + plain English summary",
            target_audience=["Customer Success Managers", "Executive stakeholders"],
            regulatory_requirements=[],
        ),
        feedback_mechanisms=[
            FeedbackMechanism(
                feedback_type="explicit",
                collection_method="Post-intervention survey: Was prediction accurate?",
                frequency="After each intervention (within 60 days)",
                integration_plan="Feed back into model retraining pipeline",
            ),
        ],
        created_at=datetime.now(timezone.utc),
        version="1.0",
    )

    # Stage 5: Ethical Risk Report
    ethical_report = EthicalRiskReport(
        initial_risks={
            EthicalPrinciple.FAIRNESS_EQUITY: [
                EthicalRisk(
                    principle=EthicalPrinciple.FAIRNESS_EQUITY,
                    risk_description=(
                        "Potential bias against smaller enterprise customers or specific industries "
                        "due to historical data imbalances"
                    ),
                    severity=RiskLevel.MEDIUM,
                    likelihood=RiskLevel.MEDIUM,
                    affected_stakeholders=["Small enterprise customers", "Emerging industry verticals"],
                    mitigation_strategies=[
                        MitigationStrategy(
                            description="Demographic parity monitoring across customer segments",
                            implementation_method=(
                                "Weekly automated fairness audits measuring precision/recall "
                                "across customer size tiers and industries"
                            ),
                            cost_estimate="$8,000 for dashboard development",
                            timeline="2 weeks",
                            effectiveness_rating=0.7,
                        ),
                        MitigationStrategy(
                            description="Balanced sampling during model training",
                            implementation_method="Stratified sampling to ensure representation",
                            cost_estimate="Included in development",
                            timeline="Ongoing",
                            effectiveness_rating=0.6,
                        ),
                    ],
                    residual_risk=RiskLevel.LOW,
                )
            ],
            EthicalPrinciple.TRANSPARENCY_ACCOUNTABILITY: [
                EthicalRisk(
                    principle=EthicalPrinciple.TRANSPARENCY_ACCOUNTABILITY,
                    risk_description="CS managers may not understand model reasoning",
                    severity=RiskLevel.MEDIUM,
                    likelihood=RiskLevel.HIGH,
                    affected_stakeholders=["CS team", "Customers"],
                    mitigation_strategies=[
                        MitigationStrategy(
                            description="SHAP-based explanations in plain language",
                            implementation_method="Feature importance + natural language generation",
                            cost_estimate="$12,000",
                            timeline="4 weeks",
                            effectiveness_rating=0.8,
                        ),
                    ],
                    residual_risk=RiskLevel.LOW,
                )
            ],
        },
        mitigation_strategies={
            "fairness": [
                MitigationStrategy(
                    description="Demographic parity monitoring across customer segments",
                    implementation_method=(
                        "Weekly automated fairness audits measuring precision/recall "
                        "across customer size tiers and industries"
                    ),
                    cost_estimate="$8,000",
                    timeline="2 weeks",
                    effectiveness_rating=0.7,
                )
            ],
            "transparency": [
                MitigationStrategy(
                    description="SHAP-based explanations in plain language",
                    implementation_method="Feature importance + natural language generation",
                    cost_estimate="$12,000",
                    timeline="4 weeks",
                    effectiveness_rating=0.8,
                )
            ],
        },
        residual_risks={
            EthicalPrinciple.FAIRNESS_EQUITY: RiskLevel.LOW,
            EthicalPrinciple.PRIVACY_PROTECTION: RiskLevel.LOW,
            EthicalPrinciple.TRANSPARENCY_ACCOUNTABILITY: RiskLevel.LOW,
            EthicalPrinciple.SAFETY_RESILIENCE: RiskLevel.LOW,
            EthicalPrinciple.HUMAN_AGENCY: RiskLevel.LOW,
        },
        governance_decision=GovernanceDecision.PROCEED,
        decision_reasoning=(
            "All residual risks are LOW after mitigation. Project demonstrates strong "
            "technical feasibility (HIGH), clear business value ($3M annual impact), and "
            "comprehensive risk mitigation plan. Recommend proceeding with quarterly "
            "fairness audits and user feedback integration."
        ),
        monitoring_plan=ContinuousMonitoringPlan(
            metrics_to_monitor=[
                "Demographic parity ratio (by customer size)",
                "False positive rate by industry vertical",
                "User satisfaction with predictions",
                "Intervention success rate",
            ],
            monitoring_frequency="weekly automated + monthly human review",
            alert_thresholds={"demographic_parity": 0.8, "false_positive_rate": 0.3},
            review_process="Weekly automated dashboard + Monthly AI Ethics Committee review",
            escalation_procedure=(
                "Halt model if demographic parity < 0.7 OR false positive rate > 0.4; "
                "Escalate to VP Engineering + Chief AI Ethics Officer"
            ),
        ),
        requires_committee_review=False,
        created_at=datetime.now(timezone.utc),
        version="1.0",
    )

    # Complete Charter
    charter = AIProjectCharter(
        session_id=uuid4(),
        project_name="B2B Customer Churn Prediction System",
        created_at=datetime.now(timezone.utc),
        completed_at=datetime.now(timezone.utc),
        problem_statement=problem_statement,
        metric_alignment_matrix=metric_alignment,
        data_quality_scorecard=data_quality,
        user_context=user_context,
        ethical_risk_report=ethical_report,
        governance_decision=GovernanceDecision.PROCEED,
        overall_feasibility=FeasibilityLevel.HIGH,
        critical_success_factors=[
            "High-quality CRM data with <15 minute lag",
            "Effective retention campaign execution by CS team",
            "User adoption and trust in model predictions",
            "Continuous fairness monitoring and mitigation",
        ],
        major_risks=[
            "Campaign fatigue reducing intervention effectiveness",
            "Data quality degradation over time",
            "Model drift as customer behavior patterns change",
            "Potential fairness issues across customer segments",
        ],
        approver=None,
        approval_date=None,
        version="1.0",
        citations=[
            Citation(
                citation_type="journal",
                authors=["Verbeke, W.", "Martens, D.", "Baesens, B."],
                year=2014,
                title="Social network analysis for customer churn prediction",
                source="Applied Soft Computing",
                doi="10.1016/j.asoc.2014.05.017",
            ),
            Citation(
                citation_type="journal",
                authors=["Hadden, J.", "Tiwari, A.", "Roy, R.", "Ruta, D."],
                year=2007,
                title="Computer assisted customer churn management: State-of-the-art and future trends",
                source="Computers & Operations Research",
                doi="10.1016/j.cor.2005.11.007",
            ),
        ],
    )

    return charter


# =============================================================================
# END-TO-END SIMULATION
# =============================================================================


async def main():
    """Run end-to-end U-AIP workflow simulation."""
    console.print("\n")
    console.print(
        Panel.fit(
            "[bold cyan]U-AIP Scoping Assistant[/bold cyan]\n"
            "[bold white]End-to-End Workflow Simulation[/bold white]\n\n"
            "[dim]This simulation demonstrates the complete U-AIP process:[/dim]\n"
            "[dim]  1. Session creation[/dim]\n"
            "[dim]  2. Multi-stage evaluation[/dim]\n"
            "[dim]  3. Reflection agent validation[/dim]\n"
            "[dim]  4. Charter generation[/dim]\n"
            "[dim]  5. Multi-format export[/dim]",
            border_style="cyan",
        )
    )
    console.print("\n")

    # =============================================================================
    # PHASE 1: DATABASE INITIALIZATION
    # =============================================================================

    console.print("[bold cyan]PHASE 1: Database Initialization[/bold cyan]")

    with console.status("[cyan]Connecting to database...", spinner="dots"):
        db_config = DatabaseConfig(
            host=os.getenv("DB_HOST", "localhost"),
            port=int(os.getenv("DB_PORT", "15432")),
            database=os.getenv("DB_NAME", "uaip_scoping"),
            user=os.getenv("DB_USER", "uaip_user"),
            password=os.getenv("DB_PASSWORD", "changeme"),
        )

        db_manager = DatabaseManager(db_config)

        try:
            await db_manager.initialize()
            console.print("  ✓ [green]Database connected successfully[/green]")
        except Exception as e:
            console.print(f"  ✗ [red]Database connection failed: {e}[/red]")
            console.print(
                "\n[yellow]Troubleshooting:[/yellow]\n"
                "  • Start database: [cyan]docker compose up -d uaip-db[/cyan]\n"
                "  • Check .env configuration"
            )
            return

    # =============================================================================
    # PHASE 2: SESSION CREATION
    # =============================================================================

    console.print("\n[bold cyan]PHASE 2: Session Creation[/bold cyan]")

    try:
        with console.status("[cyan]Creating new session...", spinner="dots"):
            session_repo = SessionRepository(db_manager)
            session = await session_repo.create_new(
                user_id="demo_user", project_name="B2B Customer Churn Prediction System"
            )

        console.print(f"  ✓ [green]Session created: {session.session_id}[/green]")
        console.print(f"    • Project: {session.project_name}")
        console.print(f"    • User: {session.user_id}")
        console.print(f"    • Status: {session.status.value}")

        # =============================================================================
        # PHASE 3: SIMULATED 5-STAGE EVALUATION
        # =============================================================================

        console.print("\n[bold cyan]PHASE 3: Five-Stage Evaluation (Simulated)[/bold cyan]")
        console.print("[dim]Note: Full agent conversation workflow is placeholder for now[/dim]\n")

        stages = [
            "Stage 1: Business Translation",
            "Stage 2: Value Quantification",
            "Stage 3: Data Feasibility",
            "Stage 4: User Centricity",
            "Stage 5: Ethical Risk Assessment",
        ]

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console,
        ) as progress:
            for i, stage_name in enumerate(stages, 1):
                task = progress.add_task(f"  {stage_name}...", total=None)
                await asyncio.sleep(0.5)  # Simulate processing
                progress.update(task, completed=True)
                console.print(f"  ✓ [green]{stage_name} completed[/green]")

        console.print("\n  [bold green]✓ All 5 stages completed successfully![/bold green]")

        # =============================================================================
        # PHASE 4: CHARTER GENERATION
        # =============================================================================

        console.print("\n[bold cyan]PHASE 4: Charter Generation[/bold cyan]")

        with console.status("[cyan]Generating charter data...", spinner="dots"):
            charter = create_sample_charter_data()
            charter.session_id = session.session_id  # Link to session

        console.print("  ✓ [green]Charter data generated[/green]")
        console.print(f"    • Problem: {charter.problem_statement.business_objective[:60]}...")
        console.print(f"    • ML Approach: {charter.problem_statement.ml_archetype.value}")
        console.print(f"    • Governance Decision: {charter.governance_decision.value}")
        console.print(f"    • Feasibility: {charter.overall_feasibility.value}")

        # Save charter to database
        with console.status("[cyan]Saving charter to database...", spinner="dots"):
            charter_repo = CharterRepository(db_manager)
            await charter_repo.create_charter(charter)

        console.print("  ✓ [green]Charter saved to database[/green]")

        # =============================================================================
        # PHASE 5: MULTI-FORMAT EXPORT
        # =============================================================================

        console.print("\n[bold cyan]PHASE 5: Multi-Format Charter Export[/bold cyan]")

        # Create output directory
        output_dir = Path("simulation_outputs")
        output_dir.mkdir(exist_ok=True)

        generator = CharterDocumentGenerator()
        exports = []

        # Markdown export
        with console.status("[cyan]Generating Markdown export...", spinner="dots"):
            markdown = await generator.generate_markdown(charter)
            md_path = output_dir / f"charter_{session.session_id}.md"
            md_path.write_text(markdown)
            exports.append(("Markdown", md_path, len(markdown)))

        console.print(f"  ✓ [green]Markdown: {md_path}[/green] ({len(markdown):,} chars)")

        # PDF export
        with console.status("[cyan]Generating PDF export...", spinner="dots"):
            pdf_bytes = await generator.generate_pdf(charter)
            pdf_path = output_dir / f"charter_{session.session_id}.pdf"
            pdf_path.write_bytes(pdf_bytes)
            exports.append(("PDF", pdf_path, len(pdf_bytes)))

        console.print(f"  ✓ [green]PDF: {pdf_path}[/green] ({len(pdf_bytes):,} bytes)")

        # JSON export
        with console.status("[cyan]Generating JSON export...", spinner="dots"):
            json_str = await generator.generate_json(charter)
            json_path = output_dir / f"charter_{session.session_id}.json"
            json_path.write_text(json_str)
            exports.append(("JSON", json_path, len(json_str)))

        console.print(f"  ✓ [green]JSON: {json_path}[/green] ({len(json_str):,} chars)")

        # =============================================================================
        # SUMMARY
        # =============================================================================

        console.print("\n")
        console.print(
            Panel.fit(
                "[bold green]✓ End-to-End Simulation Complete![/bold green]\n\n"
                "[bold]Session Details:[/bold]\n"
                f"  • Session ID: {session.session_id}\n"
                f"  • Project: {charter.project_name}\n"
                f"  • Governance: {charter.governance_decision.value.upper()}\n"
                f"  • Feasibility: {charter.overall_feasibility.value.upper()}\n\n"
                "[bold]Exported Files:[/bold]\n"
                f"  • {md_path.name}\n"
                f"  • {pdf_path.name}\n"
                f"  • {json_path.name}\n\n"
                f"[dim]All files saved to: {output_dir.absolute()}[/dim]\n\n"
                "[bold]What was demonstrated:[/bold]\n"
                "  ✓ Database session creation\n"
                "  ✓ Five-stage evaluation workflow\n"
                "  ✓ Charter data structure\n"
                "  ✓ Multi-format export (MD/PDF/JSON)\n"
                "  ✓ Database persistence\n\n"
                "[bold yellow]Next Steps:[/bold yellow]\n"
                "  • Implement actual agent conversations\n"
                "  • Add reflection agent integration\n"
                "  • Build CLI conversation loop",
                title="[bold cyan]Simulation Summary[/bold cyan]",
                border_style="green",
            )
        )

        # Display export table
        console.print("\n[bold cyan]Export Summary:[/bold cyan]\n")
        table = Table(title="Generated Charter Files")
        table.add_column("Format", style="cyan")
        table.add_column("File Path", style="white")
        table.add_column("Size", justify="right", style="yellow")

        for format_name, path, size in exports:
            table.add_row(format_name, str(path.name), f"{size:,}")

        console.print(table)

    finally:
        await db_manager.close()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        console.print("\n[yellow]Simulation interrupted by user.[/yellow]")
        sys.exit(0)
    except Exception as e:
        console.print(f"\n[bold red]Simulation failed:[/bold red] {e}")
        console.print_exception()
        sys.exit(1)
